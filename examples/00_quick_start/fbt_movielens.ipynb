{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FBT Single Node on MovieLens (Python, CPU)\n",
    "\n",
    "Lets say you are shopping online and you'd like to buy a Microsoft Surface tablet. You might add this to your shopping cart. You may then see on your screen a phrase similar to \"Frequently bought together\" with visuals and links to a Microsoft keyboard, a tablet case, a mouse and so on. Many recommendation algorithms can enable this feature under the hood. However, one of the simplest ones is exactly as the phrase describes - What are some other items that people bought along with a Microsoft surface? Which of these items are the most popular? That is essentially what is implemented in the FBT (Frequently bought together) recommender class which we work with in this notebook.\n",
    "\n",
    "FBT recommender can be thought of a simple restriction of the SAR (Simple Algorithm for Recommendation) recommender. Like SAR, FBT is a fast and scalable algorithm for personalized recommendations based on user transaction history. SAR leverages user ratings of items and timestamp information of when user rated an item to produce easily explainable and interpretable recommendations. However, there are many scenarios where we may not have reliable rating information or timestamps. All we have is user interactions with items and we need a simple recommendation engine that can leverage this interaction information without regard to context or quality of interaction or when in history did this interaction happen.\n",
    "\n",
    "This is where we can leverage FBT. Like SAR, FBT recommends items that are most ***similar*** to the ones that the user already has an existing ***affinity*** for. Two items are ***similar*** if the users that interacted with one item are also likely to have interacted with the other. Unlike SAR though, user ***affinity*** to an item is simply binary - 1 if the user has interacted with an item in the past, 0 otherwise. We don't associate quality of this interaction for this model that rating information can typically do for us.\n",
    "\n",
    "### Advantages of FBT:\n",
    "- A simple first algorithm to implement when all you have is users and items and no more information. Covers a broad range of customer scenarios.\n",
    "- High accuracy for an easy to train and deploy algorithm\n",
    "- Fast training and scoring, only requiring simple counting to construct matrices used at prediction time.\n",
    "- Easily scalable to implement in Spark for large tables of user-item interactions.\n",
    "\n",
    "### Notes to use FBT properly:\n",
    "- Since FBT uses very little information, recommendations will likely not have more context than historical interactions. If we can leverage useful information from item or user features, more sohisticated algorithms will have an edge in performance.\n",
    "\n",
    "- It's memory-hungry, requiring the creation of an $mxm$ sparse square matrix (where $m$ is the number of items). This can also be a problem for many matrix factorization algorithms.\n",
    "- FBT does not need ratings information, hence we can't predict ratings either. Evaluation can best happen with user studies. We can still look at offline evaluation methods like Precision@K, Recall@K.\n",
    "\n",
    "This notebook provides an example of how to utilize and evaluate FBT in Python on a CPU."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    rmse,\n",
    "    mae,\n",
    "    logloss,\n",
    "    rsquared,\n",
    "    exp_var\n",
    ")\n",
    "from recommenders.models.fbt.fbt import FBT\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pandas version: 1.1.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "parameters"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Download and use the MovieLens Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "col_user = 'user_id'\n",
    "col_item = 'item_id'\n",
    "col_item_name = f'{col_item}_name'\n",
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=(col_user, col_item),\n",
    "    title_col=col_item_name\n",
    ")\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:01<00:00, 3.75kKB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_id_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  item_id_name\n",
       "0      196      242  Kolya (1996)\n",
       "1       63      242  Kolya (1996)\n",
       "2      226      242  Kolya (1996)\n",
       "3      154      242  Kolya (1996)\n",
       "4      306      242  Kolya (1996)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Split the data using the python random splitter provided in utilities:\n",
    "\n",
    "We split the full dataset into a `train` and `test` dataset to evaluate performance of the algorithm against a held-out set not seen during training. Because FBT generates recommendations based on user preferences, all users that are in the test set must also exist in the training set. For this case, we can use the provided `python_stratified_split` function which holds out a percentage (in this case 25%) of items from each user, but ensures all users are in both `train` and `test` datasets. Other options are available in the `dataset.python_splitters` module which provide more control over how the split occurs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train, test = python_stratified_split(data, \n",
    "                                      ratio=0.75, \n",
    "                                      col_user=col_user, \n",
    "                                      col_item=col_item, \n",
    "                                      seed=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train[col_user].unique()),\n",
    "    train_items=len(train[col_item].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test[col_user].unique()),\n",
    "    test_items=len(test[col_item].unique()),\n",
    "))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Train:\n",
      "Total Ratings: 74992\n",
      "Unique Users: 943\n",
      "Unique Items: 1601\n",
      "\n",
      "Test:\n",
      "Total Ratings: 25008\n",
      "Unique Users: 943\n",
      "Unique Items: 1532\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Train the FBT Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "col_score = 'score'\n",
    "model = FBT(\n",
    "    col_user=col_user,\n",
    "    col_item=col_item,\n",
    "    col_score=col_score\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-14 14:40:40,547 INFO     Check input dataframe to fit() is of the type, schema we expect and there are no duplicates.\n",
      "2021-09-14 14:40:40,563 INFO     Creating index columns\n",
      "2021-09-14 14:40:40,655 INFO     Building user affinity sparse matrix\n",
      "2021-09-14 14:40:40,713 INFO     Done training\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Took 0.17020754999975907 seconds for training.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.item_frequencies"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 86, 120,  52, ...,   1,   1,   1])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(model.n_items, model.n_users)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1601 943\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Make recommendations using the FBT model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Predict 10 recommended items that user has not interacted with during training\n",
    "with Timer() as test_time:\n",
    "    topk_remove_seen = model.recommend_k_items(test=test, \n",
    "                                               top_k=10, \n",
    "                                               remove_seen=True)\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-14 14:45:18,154 INFO     Calculating recommendation scores\n",
      "2021-09-14 14:45:18,343 INFO     Removing seen items\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Took 0.216254740000295 seconds for prediction.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "topk_remove_seen.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>13800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>12657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>12159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>11940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>11808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>11528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>10883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>10776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>10580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>405</td>\n",
       "      <td>10428.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id    score\n",
       "0        1       98  13800.0\n",
       "1        1       56  12657.0\n",
       "2        1       69  12159.0\n",
       "3        1      423  11940.0\n",
       "4        1      204  11808.0\n",
       "5        1      117  11528.0\n",
       "6        1      288  10883.0\n",
       "7        1      183  10776.0\n",
       "8        1      238  10580.0\n",
       "9        1      405  10428.0"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Predict 10 recommendations while retaining any items \n",
    "# user has already interacted with during training\n",
    "with Timer() as test_time:\n",
    "    topk_keep_seen = model.recommend_k_items(test=test, top_k=10, remove_seen=False)\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-14 14:46:23,063 INFO     Calculating recommendation scores\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Took 0.2068116420014121 seconds for prediction.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "topk_keep_seen.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>16763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>15297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>15081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>13913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>13800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>13776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>13513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>12923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>12897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  score\n",
       "0        1       50  16763\n",
       "1        1      181  15297\n",
       "2        1      174  15081\n",
       "3        1        1  14654\n",
       "4        1      100  13913\n",
       "5        1       98  13800\n",
       "6        1      172  13776\n",
       "7        1      210  13513\n",
       "8        1      121  12923\n",
       "9        1      222  12897"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Adding titles of recommended items for novel recommendations not seen during training\n",
    "topk_remove_seen_with_titles = (\n",
    "    topk_remove_seen.merge((\n",
    "        data.loc[:, [col_item, col_item_name]]\n",
    "            .drop_duplicates()\n",
    "            .set_index(col_item)\n",
    "    ), on=col_item, how='inner')\n",
    "    .sort_values(by=[col_user, col_score], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "        \n",
    "topk_remove_seen_with_titles.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>item_id_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>12657.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>12159.0</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>11940.0</td>\n",
       "      <td>E.T. the Extra-Terrestrial (1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>11808.0</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>11528.0</td>\n",
       "      <td>Rock, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>10883.0</td>\n",
       "      <td>Scream (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>10776.0</td>\n",
       "      <td>Alien (1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>10580.0</td>\n",
       "      <td>Raising Arizona (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>405</td>\n",
       "      <td>10428.0</td>\n",
       "      <td>Mission: Impossible (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id    score                       item_id_name\n",
       "0        1       98  13800.0   Silence of the Lambs, The (1991)\n",
       "1        1       56  12657.0                Pulp Fiction (1994)\n",
       "2        1       69  12159.0                Forrest Gump (1994)\n",
       "3        1      423  11940.0  E.T. the Extra-Terrestrial (1982)\n",
       "4        1      204  11808.0          Back to the Future (1985)\n",
       "5        1      117  11528.0                   Rock, The (1996)\n",
       "6        1      288  10883.0                      Scream (1996)\n",
       "7        1      183  10776.0                       Alien (1979)\n",
       "8        1      238  10580.0             Raising Arizona (1987)\n",
       "9        1      405  10428.0         Mission: Impossible (1996)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Looking at top 10 titles for userid = 1\n",
    "topk_keep_seen_with_titles = (\n",
    "    topk_keep_seen.merge((\n",
    "        data.loc[:, [col_item, col_item_name]]\n",
    "            .drop_duplicates()\n",
    "            .set_index(col_item)\n",
    "    ), on=col_item, how='inner')\n",
    "    .sort_values(by=[col_user, col_score], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "        \n",
    "topk_keep_seen_with_titles.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>item_id_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>16763</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>15297</td>\n",
       "      <td>Return of the Jedi (1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>15081</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14654</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>13913</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>13800</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>13776</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>13513</td>\n",
       "      <td>Indiana Jones and the Last Crusade (1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>12923</td>\n",
       "      <td>Independence Day (ID4) (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>12897</td>\n",
       "      <td>Star Trek: First Contact (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  score                               item_id_name\n",
       "0        1       50  16763                           Star Wars (1977)\n",
       "1        1      181  15297                  Return of the Jedi (1983)\n",
       "2        1      174  15081             Raiders of the Lost Ark (1981)\n",
       "3        1        1  14654                           Toy Story (1995)\n",
       "4        1      100  13913                               Fargo (1996)\n",
       "5        1       98  13800           Silence of the Lambs, The (1991)\n",
       "6        1      172  13776            Empire Strikes Back, The (1980)\n",
       "7        1      210  13513  Indiana Jones and the Last Crusade (1989)\n",
       "8        1      121  12923              Independence Day (ID4) (1996)\n",
       "9        1      222  12897            Star Trek: First Contact (1996)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. Evaluate how well FBT performs\n",
    "\n",
    "We evaluate how well FBT performs for a few common ranking metrics provided in the `python_evaluation` module in reco_utils. We will consider the Mean Average Precision (MAP), Normalized Discounted Cumalative Gain (NDCG), Precision, and Recall for the top-k items per user we computed with FBT. User and item column names are specified in each evaluation method. Since FBT does not have ratings information, we create a dummy column with all values set to 1.0 so as to conform to the metrics signature."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "test['rating'] = 1\n",
    "eval_map_k = map_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score,k=TOP_K)\n",
    "print(f\"MAP@{TOP_K}: {eval_map_k}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAP@10: 0.0700594112753097\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "eval_ndcg = ndcg_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "print(f\"NDCG@{TOP_K}: {eval_ndcg}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NDCG@10: 0.30469469553920064\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "eval_precision = precision_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "print(f\"Precision@{TOP_K}: {eval_precision}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision@10: 0.26521739130434785\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "eval_recall = recall_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "print(f\"Recall@{TOP_K}: {eval_recall}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall@10: 0.1250000517480203\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "eval_rmse = rmse(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score)\n",
    "print(f\"RMSE: {eval_rmse}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 8901.019858835787\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "eval_mae = mae(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score)\n",
    "print(f\"MAE: {eval_mae}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 7699.956417433027\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(f\"Model:\\t\",\n",
    "      f\"Top K: {TOP_K}\",\n",
    "      f\"MAP@{TOP_K}: {eval_map_k}\",\n",
    "      f\"NDCG@{TOP_K}: {eval_ndcg}\",\n",
    "      f\"Precision@{TOP_K}: {eval_precision}\",\n",
    "      f\"Recall@{TOP_K}: {eval_recall}\",\n",
    "      f\"RMSE: {eval_rmse}\",\n",
    "      f\"MAE: {eval_mae}\",\n",
    "      sep='\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model:\t\n",
      "Top K: 10\n",
      "MAP@10: 0.0700594112753097\n",
      "NDCG@10: 0.30469469553920064\n",
      "Precision@10: 0.26521739130434785\n",
      "Recall@10: 0.1250000517480203\n",
      "RMSE: 8901.019858835787\n",
      "MAE: 7699.956417433027\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Now let's look at the results for a specific user\n",
    "user_id = 1\n",
    "\n",
    "ground_truth = test[test[col_user]==user_id]\n",
    "prediction = topk_remove_seen[topk_remove_seen[col_user]==user_id].sort_values(by=col_score, ascending=False)[:TOP_K]\n",
    "test_user_movie_watched_prediction = (\n",
    "    pd.merge(ground_truth, prediction, on=[col_user, col_item], how='left')\n",
    "      .drop(columns=['rating'])\n",
    ")\n",
    "test_user_movie_watched_prediction.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_id_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>I.Q. (1994)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>12159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>Breaking the Waves (1996)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>Love Bug, The (1969)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id               item_id_name    score\n",
       "0        1       49                I.Q. (1994)      NaN\n",
       "1        1       69        Forrest Gump (1994)  12159.0\n",
       "2        1      221  Breaking the Waves (1996)      NaN\n",
       "3        1        5             Copycat (1995)      NaN\n",
       "4        1      139       Love Bug, The (1969)      NaN"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above, we see that one of the movies from the test set was recovered by the model's top-k recommendations, however the others were not. Offline evaluations are difficult as they can only use what was seen previously in the test set and may not represent the user's actual preferences across the entire set of items. Adjustments to how the data is split, algorithm is used and hyper-parameters can improve the results here. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Record results with papermill for tests - ignore this cell\n",
    "sb.glue(\"map\", eval_map_k)\n",
    "sb.glue(\"ndcg\", eval_ndcg)\n",
    "sb.glue(\"precision\", eval_precision)\n",
    "sb.glue(\"recall\", eval_recall)\n",
    "sb.glue(\"train_time\", train_time.interval)\n",
    "sb.glue(\"test_time\", test_time.interval)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "map",
       "data": 0.044028595315000515,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "map",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "ndcg",
       "data": 0.2443432424633656,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "ndcg",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "precision",
       "data": 0.2292682926829268,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "precision",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "recall",
       "data": 0.09436047878760673,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "recall",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "train_time",
       "data": 2.5096962659736164,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "train_time",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "test_time",
       "data": 4.707005217962433,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "test_time",
       "data": true,
       "display": false
      }
     }
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.11 64-bit ('reco_base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "interpreter": {
   "hash": "98169291db0c76b5a29ac985497b93ea6e9ffb789b0c6c3e8a1bf753f6a69f0f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}